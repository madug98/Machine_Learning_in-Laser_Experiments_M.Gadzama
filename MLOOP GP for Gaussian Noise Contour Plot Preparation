#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Dec  3 16:10:02 2020

@author: madugadzama
"""
'''There was a necessity to change the previous Gaussian Process code. Firstly, it needed to be updated such that 
one could run with GP, looping through combinations of different parameters. In this example, we have the aim of 
collecting data for a contour plot in order to observe the correlations between parameters. The motivation 
behind this was to investigate whether the increasing of noise had any effect on the correlations, and whether
the contour plots broke down. We changed the code such that in each run, it would apply the GP for different combinations
of two parameters (allowing the other two to re-optimise) and then calculate the chi-squared values. This values are then 
collected and used to create a contour plot.''' 




#Imports for python 2 compatibility
from __future__ import absolute_import, division, print_function
__metaclass__ = type

#Imports for M-LOOP
import mloop.interfaces as mli
import mloop.controllers as mlc
import mloop.visualizations as mlv

#Other imports
import numpy as np
import time

import matplotlib.pyplot as plt
from timeit import default_timer as timer 


#starting a timer
t1_start = time.process_time()


#define the Lorentzian Linewidth
def linewidth(x, s_bgd, s_0, x_0, d_x):
    return s_bgd + s_0/(1+4*((x-x_0)/d_x)**2)

# setting true paramter values
background = 2
s_0 = 8 # height of peak
x_0 = 50 # centre of peak
d_x = 10 # angular width of peak

#setting the number of repeats for the obtaining of our 'experimental data' 
number_of_runs = 10

#setting the variance of noise
noise_variance= 4.2

# setting the x values and corresponding linewidth values
x = np.linspace(0,100,200)
y = linewidth(x,background,s_0,x_0,d_x) # this is the linewidth before noisy is added


'''I am just going to use a variance in the noise of 2.2'''


y_1 = np.loadtxt('exp_1_var_9.2.txt')
y_2 =np.loadtxt('exp_2_var_9.2.txt')
y_3 =np.loadtxt('exp_3_var_9.2.txt')
y_4 =np.loadtxt('exp_4_var_9.2.txt') 
y_5 = np.loadtxt('exp_5_var_9.2.txt')
y_6 =np.loadtxt('exp_6_var_9.2.txt')
y_7 =np.loadtxt('exp_7_var_9.2.txt')
y_8 =np.loadtxt('exp_8_var_9.2.txt') 
y_9 = np.loadtxt('exp_9_var_9.2.txt')
y_10 =np.loadtxt('exp_10_var_9.2.txt')


# Finding the mean and standard error of 

mean = [] # this is the data we are plotting originally as our 'noisy data' 
standard_error = []

# using the zip function method to find mean and std
a = list(zip(y_1,y_2,y_3,y_4,y_5,y_6,y_7,y_8,y_9,y_10))

for i in range(len(a)):
    mean.append((np.sum(a[i])/number_of_runs))
    standard_error.append(np.std(a[i])/np.sqrt(number_of_runs)) 

#plotting the noisy lorentzian with error bars 
plt.errorbar(x, mean, yerr=standard_error, marker = '.', linestyle = 'None')
plt.xlabel('Scattering Angle')
plt.ylabel('Diffracted Intensity')
plt.show()     

#making an array of standard error values squared
standard_error_squared = [] 
for i in range(len(standard_error)):
    standard_error_squared.append(standard_error[i]**2)


#turn lists into numpy arrays
standard_error = np.array(standard_error)

#defining our cost function to minimise
def chi_squared(x, s_bgd, s_0, x_0, d_x):
    return np.sum((mean -linewidth(x, s_bgd, s_0, x_0, d_x))**2/ standard_error**2)

def least_squares(x, s_bgd, s_0, x_0, d_x):
    return np.sum((mean -linewidth(x, s_bgd, s_0, x_0, d_x)**2))



''' We are going to use the same method, but this time we will vary the background and peak height. 
We will then collect the cost, but this time we will also collect the other two parameters.'''



background_variation = -2
background_variation_min = -2
background_variation_max = 7.00000001
background_variation_step = 1
background_variation_array = np.arange(background_variation_min,background_variation_max,background_variation_step)

peak_height_variation = 3
peak_height_variation_min = 3
peak_height_variation_max = 12.0000001
peak_height_variation_step = 1
peak_height_variation_array = np.arange(peak_height_variation_min,peak_height_variation_max,peak_height_variation_step)



percentage_counter = 0

#Declare your custom class that inherets from the Interface class
class CustomInterface(mli.Interface):
    
    #Initialization of the interface, including this method is optional
    def __init__(self):
        #You must include the super command to call the parent class, Interface, constructor 
        super(CustomInterface,self).__init__()
        
        
        #Attributes of the interface can be added here
        #If you want to precalculate any variables etc. this is the place to do it
        #In this example we will just define the location of the minimum
        #self.minimum_params = np.array([0,0.1,-0.1])
        
        
    #You must include the get_next_cost_dict method in your class
    #this method is called whenever M-LOOP wants to run an experiment
    def get_next_cost_dict(self,params_dict):
        
        #Get parameters from the provided dictionary
        params = params_dict['params']
        #g = _1gaussian(x, params[0], params[1], params[2])
        #Here you can include the code to run your experiment given a particular set of parameters
        #In this example we will just evaluate a sum of sinc functions
        #cost = snr_distance(0.1, params)
        cost = np.sum(chi_squared(x, background_variation, peak_height_variation,params[0], params[1])) #1.94 not been run yet
        #There is no uncertainty in our result
        uncer = 0
        #The evaluation will always be a success
        bad = False
        #Add a small time delay to mimic a real experiment
        
        
        #The cost, uncertainty and bad boolean must all be returned as a dictionary
        #You can include other variables you want to record as well if you want
        cost_dict = {'cost':cost, 'uncer':uncer, 'bad':bad}
        return cost_dict
    
def main():
    #M-LOOP can be run with three commands
    
    #First create your interface
    interface = CustomInterface()
    #Next create the controller. Provide it with your interface and any options you want to set
    
    controller = mlc.create_controller(interface, 
                                       max_num_runs = 500,
                                       target_cost = 0.01,
                                       num_params = 2, 
                                       min_boundary = [45,5],
                                       max_boundary = [55,15])
    #To run M-LOOP and find the optimal parameters just use the controller method optimize
    controller.optimize()

     #The results of the optimization will be saved to files and can also be accessed as attributes of the controller.
    print('The other two optimised parameters which werent varied are:', controller.best_params)
    
    print('The CHI-SQUARED to be used for contouring:',controller.best_cost)
    print('currently: background = ', background_variation,'and peak height=', peak_height_variation)
    
    print('we are currently',100*percentage_counter/(len(background_variation_array)*len(peak_height_variation_array )),
          'percent of the way through!' )
    
    #You can also run the default sets of visualizations for the controller with one command
    mlv.show_all_default_visualizations(controller)
    
    cost_array = np.array(controller.best_cost)
    centre_x0_array = np.array(controller.best_params[0])
    width_dx_array = np.array(controller.best_params[1])
    
    '''In this part, I am taking the CHI-Squared value, appending it to an array and then saving 
    that updated array on each iteration in the loop. I will also saved the other two corresponding 
    parameter values that have been obtained'''
    
    cost_array_to_save1 = np.append(np.loadtxt('week_9_collection_chi_squared_background_peak_height3.txt'),cost_array)
    centre_to_save = np.append(np.loadtxt('week_9_collection_chi_squared_background_peak_height_1_centre_value_3.txt'),centre_x0_array)
    width_to_save = np.append(np.loadtxt('week_9_collection_chi_squared_background_peak_height_1_peak_width_value_3.txt'),width_dx_array )
    
    np.savetxt('week_9_collection_chi_squared_background_peak_height3.txt', cost_array_to_save1)
    np.savetxt('week_9_collection_chi_squared_background_peak_height_1_centre_value_3.txt', centre_to_save)
    np.savetxt('week_9_collection_chi_squared_background_peak_height_1_peak_width_value_3.txt', width_to_save)
    
    
    

'''Explaination of what is going on:
    Here, I am looping the main function. The for parts mean that every value in 
    background_variation_array is tested with every other value in peak_centre_variation_array.
    We have to use an actual single value in the custom interface, so rather than using the
    arrays, I am setting the current single value of background and peak centreequal to the current 
    values that we are in the arrays. I also increase the percentage_counter by 1 each time, 
    which lets us find the percentage of the way through that we are at. '''
    
    
    
for i in range(len(background_variation_array)):
    for j in range(len(peak_height_variation_array)):
        
        background_variation = background_variation_array[i]
        peak_height_variation = peak_height_variation_array[j]
        percentage_counter+=1
        if __name__ == '__main__':
            main()


# just the time taken for MLOOP to run
t1_stop= time.process_time()
print('time taken is:', t1_stop-t1_start)
